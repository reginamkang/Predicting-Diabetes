best_params3 <- c(paste("eta =",as.character(eta),", max_depth =",as.character(depth),", subsample =",as.character(sub)))
}
}
}
}
best_xg_te # 0.05968468
best_params3 # "eta = 0.2 , max_depth = 7 , subsample = 0.9" for 0.5%
# make new model with best params
set.seed(123)
xgboost2 <- xgboost(data=as.matrix(diabetestrain[,-1]), label = as.matrix(diabetestrain$Diabetes_binary), nrounds = 10, cv.folds = 5, objective="binary:logistic", eta = 0.2, max_depth = 7, subsample = 0.9)
## summary model
## Which variances are important
summary(xgboost2)
# importance
xgboost_importance <- xgb.importance(model=xgboost2)
xgboost_importance
## Training error
pred3xgboost <- predict(xgboost2, newdata = as.matrix(diabetestrain[,-1]), type="response")
pred3xgboost[1:10]
y1hat4 <- ifelse(pred3xgboost < 0.5, 0, 1)
y1hat4[1:10]
sum(y1hat4 != y1)/length(y1)  ##Training error = 0.05968468
## Testing Error
y2hat3 <- ifelse(predict(gbm.diabetes3, newdata = diabetestest[,-1], n.trees=perf_gbm3, type="response") < 0.5, 0, 1)
mean(y2hat3 != y2)
######################################################################################################
B= 50; ### number of loops
TEALL = NULL; ### Final Test Error values
TrEALL = NULL ### Final Training Error values
PrecisionALL = NULL;
RecallALL = NULL;
F1ALL = NULL;
AUCALL = NULL;
set.seed(123)
n = dim(sample_diabetes)[1]; ### total number of observations
n1 = round(n * 3 / 10); ### number of observations randomly selected for testing data
for (b in 1:B){
set.seed(b)
flag <- sort(sample(1:n, n1));
train <- sample_diabetes[-flag,];
test <- sample_diabetes[flag,];
cverror <- NULL;
cverror_train <- NULL;
cvprecision <- NULL;
cvrecall <- NULL;
cvF1 <- NULL
cvAUC <- NULL
ytrue <- test$Diabetes_binary;
ytrue_tr <- train$Diabetes_binary;
## A comparison with other methods
## Testing errors of several algorithms on the diabetes dataset:
# using features from AIC feature selection: HighBP + HighChol + BMI + HeartDiseaseorAttack + GenHlth + MentHlth + Age
# at 20% of balanced data --- using features from AIC feature selection: HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income
set.seed(b)
modA <- glm(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income, family = binomial(link="logit"), data=train)
y2hatA <- ifelse(predict(modA, test[,-1], type="response" ) < 0.5, 0, 1)
lr_te <- sum(y2hatA != ytrue)/length(ytrue)
y2hatA_tr <- ifelse(predict(modA, train[,-1], type="response" ) < 0.5, 0, 1)
lr_tre <- sum(y2hatA_tr != ytrue_tr)/length(ytrue_tr)
lr_cm <- confusionMatrix(factor(y2hatA, levels=unique(c(y2hatA,ytrue))), factor(ytrue, levels=unique(c(y2hatA,ytrue))))
cvprecision <- c(cvprecision, lr_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, lr_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(lr_cm$byClass["Pos Pred Value"]*lr_cm$byClass["Sensitivity"])/(lr_cm$byClass["Pos Pred Value"]+lr_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatA), response=as.numeric(ytrue))));
cverror <- c(cverror, lr_te);
cverror_train <- c(cverror_train, lr_tre);
#B.Linear Discriminant Analysis
library(MASS)
set.seed(b)
modB <- lda(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income, data=train)
y2hatB <- predict(modB, test[,-1])$class
lda_te <- mean( y2hatB  != ytrue)
y2hatB_tr <- predict(modB, train[,-1])$class
lda_tre <- mean( y2hatB_tr  != ytrue_tr)
cverror <- c(cverror, lda_te);
cverror_train <- c(cverror_train, lda_tre);
lda_cm <- confusionMatrix(factor(y2hatB, levels=unique(c(y2hatB,ytrue))), factor(ytrue, levels=unique(c(y2hatB,ytrue))))
cvprecision <- c(cvprecision, lda_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, lda_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(lda_cm$byClass["Pos Pred Value"]*lda_cm$byClass["Sensitivity"])/(lda_cm$byClass["Pos Pred Value"]+lda_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatB), response=as.numeric(ytrue))));
## C. Naive Bayes
library(e1071)
set.seed(b)
modC <- naiveBayes(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income, data = train)
y2hatC <- predict(modC, newdata = test[,-1])
y2hatC_tr <- predict(modC, newdata = train[,-1])
nb_te <- mean( y2hatC != ytrue)
nb_tre <- mean( y2hatC_tr  != ytrue_tr)
cverror <- c(cverror, nb_te);
cverror_train <- c(cverror_train, nb_tre);
nb_cm <- confusionMatrix(factor(y2hatC, levels=unique(c(y2hatC,ytrue))), factor(ytrue, levels=unique(c(y2hatC,ytrue))))
cvprecision <- c(cvprecision, nb_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, nb_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(nb_cm$byClass["Pos Pred Value"]*nb_cm$byClass["Sensitivity"])/(nb_cm$byClass["Pos Pred Value"]+nb_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatC), response=as.numeric(ytrue))));
#D: a single Tree
library(rpart)
set.seed(b)
modE0 <- rpart(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income,data=train, method="class", parms=list(split="gini"))
opt <- which.min(modE0$cptable[, "xerror"]);
cp1 <- modE0$cptable[opt, "CP"];
modE <- prune(modE0,cp=cp1);
y2hatD <-  predict(modE, test[,-1],type="class")
y2hatD_tr <-  predict(modE, train[,-1],type="class")
st_te <- mean(y2hatD != ytrue)
st_tre <- mean(y2hatD_tr != ytrue_tr)
cverror <- c(cverror, st_te);
cverror_train <- c(cverror_train, st_tre);
st_cm <- confusionMatrix(factor(y2hatD, levels=unique(c(y2hatD,ytrue))), factor(ytrue, levels=unique(c(y2hatD,ytrue))))
cvprecision <- c(cvprecision, st_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, st_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(st_cm$byClass["Pos Pred Value"]*st_cm$byClass["Sensitivity"])/(st_cm$byClass["Pos Pred Value"]+st_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatD), response=as.numeric(ytrue))));
#E: random forest with my chosen parameters
# best params are ntree=500, mtry=5, and nodesize=7, so use these to fit a new random forest model
set.seed(b)
rf3 <- randomForest(as.factor(Diabetes_binary) ~., data=train, ntree=300, mtry=1, nodesize=5, importance=TRUE)
y2hatE = predict(rf3, test[,-1], type='class')
y2hatE_tr = predict(rf3, train[,-1], type='class')
rf_te <- mean(y2hatE != ytrue)
rf_tre <- mean(y2hatE_tr != ytrue_tr)
cverror <- c(cverror, rf_te);
cverror_train <- c(cverror_train, rf_tre);
rf_cm <- confusionMatrix(factor(y2hatE, levels=unique(c(y2hatE,ytrue))), factor(ytrue, levels=unique(c(y2hatE,ytrue))))
cvprecision <- c(cvprecision, rf_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, rf_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(rf_cm$byClass["Pos Pred Value"]*rf_cm$byClass["Sensitivity"])/(rf_cm$byClass["Pos Pred Value"]+rf_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatE), response=as.numeric(ytrue))));
#F: gbm with my chosen parameters
set.seed(b)
gbm.diabetes3 <- gbm(Diabetes_binary~.,data=train,
distribution = 'bernoulli',
n.trees = 500,
shrinkage = 0.2,
interaction.depth = 5,
cv.folds = 5)
## Model Inspection
set.seed(b)
perf_gbm3 = gbm.perf(gbm.diabetes3, method="cv",plot.it = FALSE)
y2hatF <- ifelse(predict(gbm.diabetes3, newdata = test[,-1], n.trees=perf_gbm3, type="response") < 0.5, 0, 1)
y2hatF_tr <- ifelse(predict(gbm.diabetes3, newdata = train[,-1], n.trees=perf_gbm3, type="response") < 0.5, 0, 1)
gbm_te <- mean(y2hatF != ytrue)
gbm_tre <- mean(y2hatF_tr != ytrue_tr)
cverror <- c(cverror, gbm_te);
cverror_train <- c(cverror_train, gbm_tre);
gbm_cm <- confusionMatrix(factor(y2hatF, levels=unique(c(y2hatF,ytrue))), factor(ytrue, levels=unique(c(y2hatF,ytrue))))
cvprecision <- c(cvprecision, gbm_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, gbm_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(gbm_cm$byClass["Pos Pred Value"]*gbm_cm$byClass["Sensitivity"])/(gbm_cm$byClass["Pos Pred Value"]+gbm_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatF), response=as.numeric(ytrue))));
#G: xbgboost with my chosen parameters
set.seed(b)
xgboost3 <- xgboost(data=as.matrix(diabetestrain[,-1]),
label = as.matrix(diabetestrain$Diabetes_binary),
nrounds = 10,
objective="binary:logistic",
eta = 0.2,
max_depth = 7,
subsample = 0.9)
y2hatG <- ifelse(predict(xgboost3, newdata = as.matrix(test[,-1]), type="response") < 0.5, 0, 1)
y2hatG_tr <- ifelse(predict(xgboost3, newdata = as.matrix(train[,-1]), type="response") < 0.5, 0, 1)
xgb_te <- mean(y2hatG != ytrue)
xgb_tre <- mean(y2hatG_tr != ytrue_tr)
cverror <- c(cverror, xgb_te);
cverror_train <- c(cverror_train, xgb_tre);
xg_cm <- confusionMatrix(factor(y2hatG, levels=unique(c(y2hatG,ytrue))), factor(ytrue, levels=unique(c(y2hatG,ytrue))))
cvprecision <- c(cvprecision, xg_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, xg_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(xg_cm$byClass["Pos Pred Value"]*xg_cm$byClass["Sensitivity"])/(xg_cm$byClass["Pos Pred Value"]+xg_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatG), response=as.numeric(ytrue))));
TEALL = rbind(TEALL, cverror);
TrEALL = rbind(TrEALL, cverror_train);
PrecisionALL = rbind(PrecisionALL, cvprecision);
RecallALL = rbind(RecallALL, cvrecall);
F1ALL = rbind(F1ALL, cvF1);
AUCALL = rbind(AUCALL, cvAUC);
}
dim(TEALL); ### This should be a Bx6
colnames(TEALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(TrEALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(PrecisionALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(RecallALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(F1ALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(AUCALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
## You can report the sample mean and sample variances for the 6 models
mean_tre <- apply(TrEALL, 2, function(x) mean(x, na.rm=TRUE));
var_tre <- apply(TrEALL, 2, function(x) var(x, na.rm=TRUE));
mean_te <- apply(TEALL, 2, function(x) mean(x, na.rm=TRUE));
var_te <- apply(TEALL, 2, function(x) var(x, na.rm=TRUE));
mean_precision <- apply(PrecisionALL, 2, function(x) mean(x, na.rm=TRUE));
var_precision <- apply(PrecisionALL, 2, function(x) var(x, na.rm=TRUE));
mean_recall <- apply(RecallALL, 2, function(x) mean(x, na.rm=TRUE));
var_recall <- apply(RecallALL, 2, function(x) var(x, na.rm=TRUE));
mean_f1 <- apply(F1ALL, 2, function(x) mean(x, na.rm=TRUE));
var_f1 <- apply(F1ALL, 2, function(x) var(x, na.rm=TRUE));
mean_auc <- apply(AUCALL, 2, function(x) mean(x, na.rm=TRUE));
var_auc <- apply(AUCALL, 2, function(x) var(x, na.rm=TRUE));
best_tre <- sort((mean_tre))
best_tre
best_te <- sort((mean_te))
best_te
best_precision <- sort((mean_precision))
best_precision
best_recall <- sort((mean_recall))
best_recall
best_f1 <- sort((mean_f1))
best_f1
best_auc <- sort((mean_auc))
best_auc
best_var_te
# histograms of top 4 variables chosen by feature selection
hist(sample_diabetes$Diabetes_binary, main ="Histogram of Diabetes_binary", xlab="Diabetes_binary")
hist(sample_diabetes$HighBP, main ="Histogram of HighBP", xlab="HighBP")
hist(sample_diabetes$HighChol, main ="Histogram of HighChol", xlab="HighChol")
hist(sample_diabetes$CholCheck, main ="Histogram of CholCheck", xlab="CholCheck")
hist(sample_diabetes$BMI, main ="Histogram of BMI", xlab="BMI")
# boxplots of top 4 variables chosen by feature selection
boxplot(sample_diabetes$Diabetes_binary, main ="Boxplot of Diabetes_binary", xlab="Diabetes_binary")
# boxplots of top 4 variables chosen by feature selection
boxplot(sample_diabetes$Diabetes_binary, main ="Boxplot of Diabetes_binary", xlab="Diabetes_binary")
boxplot(sample_diabetes$HighBP, main ="Boxplot of HighBP", xlab="HighBP")
boxplot(sample_diabetes$HighChol, main ="Boxplot of HighChol", xlab="HighChol")
boxplot(sample_diabetes$CholCheck, main ="Boxplot of CholCheck", xlab="CholCheck")
boxplot(sample_diabetes$BMI, main ="Boxplot of BMI", xlab="BMI")
######################################################################################################
# variable selection for non-ensemble methods:
set.seed(123)
full_model <- glm(as.factor(Diabetes_binary) ~., family = binomial(link="logit"), data=diabetestrain)
model_select_variables  <- stats::step(full_model, direction = "both");
## see coefficients of model_select_variables
round(coef(model_select_variables),3)
summary(model_select_variables)
# vif to check for multicollinearity
vif_results <- vif(full_model)
print(vif_results)
min_cverror # 0.1498127
best_params # best params are ntree=500, mtry=5, and nodesize=7
rf3 <- randomForest(as.factor(Diabetes_binary) ~., data=diabetestrain, ntree = 100 , mtry = 1 , nodesize = 4, importance=TRUE)
## Prediction on the testing data set
# type = 'class' if doing classification
rf3.pred = predict(rf3, diabetestest[,-1], type='class')
# misclassification rate
table(rf3.pred, y2)
acc3 = mean(rf3.pred == y2)
te3 <- 1 - acc3 # 0.1128609
te3
best_gbm_te # 0.115991
best_params2 # best params are "shrinkage = 0.05 , interaction.depth = 5" for 0.5%
# make new model with best params
set.seed(123)
gbm.diabetes3 <- gbm(Diabetes_binary~.,data=diabetestrain,
distribution = 'bernoulli',
n.trees = 500,
shrinkage = 0.15,
interaction.depth = 5,
cv.folds = 5)
## Model Inspection
## Find the estimated optimal number of iterations of trees - important so we don't overfit our training data
# and we'll have poor performance on testing data
perf_gbm3 = gbm.perf(gbm.diabetes3, method="cv")
perf_gbm3 # 70 at 0.5% # 37 at 20% of balanced
best_params3 # "eta = 0.2 , max_depth = 7 , subsample = 0.9" for 0.5%
######################################################################################################
B= 50; ### number of loops
TEALL = NULL; ### Final Test Error values
TrEALL = NULL ### Final Training Error values
PrecisionALL = NULL;
RecallALL = NULL;
F1ALL = NULL;
AUCALL = NULL;
set.seed(123)
n = dim(sample_diabetes)[1]; ### total number of observations
n1 = round(n * 3 / 10); ### number of observations randomly selected for testing data
for (b in 1:B){
set.seed(b)
flag <- sort(sample(1:n, n1));
train <- sample_diabetes[-flag,];
test <- sample_diabetes[flag,];
cverror <- NULL;
cverror_train <- NULL;
cvprecision <- NULL;
cvrecall <- NULL;
cvF1 <- NULL
cvAUC <- NULL
ytrue <- test$Diabetes_binary;
ytrue_tr <- train$Diabetes_binary;
## A comparison with other methods
## Testing errors of several algorithms on the diabetes dataset:
# using features from AIC feature selection: HighBP + HighChol + BMI + HeartDiseaseorAttack + GenHlth + MentHlth + Age
# at 20% of balanced data --- using features from AIC feature selection: HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income
set.seed(b)
modA <- glm(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income, family = binomial(link="logit"), data=train)
y2hatA <- ifelse(predict(modA, test[,-1], type="response" ) < 0.5, 0, 1)
lr_te <- sum(y2hatA != ytrue)/length(ytrue)
y2hatA_tr <- ifelse(predict(modA, train[,-1], type="response" ) < 0.5, 0, 1)
lr_tre <- sum(y2hatA_tr != ytrue_tr)/length(ytrue_tr)
lr_cm <- confusionMatrix(factor(y2hatA, levels=unique(c(y2hatA,ytrue))), factor(ytrue, levels=unique(c(y2hatA,ytrue))))
cvprecision <- c(cvprecision, lr_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, lr_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(lr_cm$byClass["Pos Pred Value"]*lr_cm$byClass["Sensitivity"])/(lr_cm$byClass["Pos Pred Value"]+lr_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatA), response=as.numeric(ytrue))));
cverror <- c(cverror, lr_te);
cverror_train <- c(cverror_train, lr_tre);
#B.Linear Discriminant Analysis
library(MASS)
set.seed(b)
modB <- lda(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income, data=train)
y2hatB <- predict(modB, test[,-1])$class
lda_te <- mean( y2hatB  != ytrue)
y2hatB_tr <- predict(modB, train[,-1])$class
lda_tre <- mean( y2hatB_tr  != ytrue_tr)
cverror <- c(cverror, lda_te);
cverror_train <- c(cverror_train, lda_tre);
lda_cm <- confusionMatrix(factor(y2hatB, levels=unique(c(y2hatB,ytrue))), factor(ytrue, levels=unique(c(y2hatB,ytrue))))
cvprecision <- c(cvprecision, lda_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, lda_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(lda_cm$byClass["Pos Pred Value"]*lda_cm$byClass["Sensitivity"])/(lda_cm$byClass["Pos Pred Value"]+lda_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatB), response=as.numeric(ytrue))));
## C. Naive Bayes
library(e1071)
set.seed(b)
modC <- naiveBayes(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income, data = train)
y2hatC <- predict(modC, newdata = test[,-1])
y2hatC_tr <- predict(modC, newdata = train[,-1])
nb_te <- mean( y2hatC != ytrue)
nb_tre <- mean( y2hatC_tr  != ytrue_tr)
cverror <- c(cverror, nb_te);
cverror_train <- c(cverror_train, nb_tre);
nb_cm <- confusionMatrix(factor(y2hatC, levels=unique(c(y2hatC,ytrue))), factor(ytrue, levels=unique(c(y2hatC,ytrue))))
cvprecision <- c(cvprecision, nb_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, nb_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(nb_cm$byClass["Pos Pred Value"]*nb_cm$byClass["Sensitivity"])/(nb_cm$byClass["Pos Pred Value"]+nb_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatC), response=as.numeric(ytrue))));
#D: a single Tree
library(rpart)
set.seed(b)
modE0 <- rpart(as.factor(Diabetes_binary) ~ HighBP + HighChol + CholCheck + BMI + Stroke + HeartDiseaseorAttack + Veggies + HvyAlcoholConsump + AnyHealthcare + NoDocbcCost + GenHlth + PhysHlth + Sex + Age + Income,data=train, method="class", parms=list(split="gini"))
opt <- which.min(modE0$cptable[, "xerror"]);
cp1 <- modE0$cptable[opt, "CP"];
modE <- prune(modE0,cp=cp1);
y2hatD <-  predict(modE, test[,-1],type="class")
y2hatD_tr <-  predict(modE, train[,-1],type="class")
st_te <- mean(y2hatD != ytrue)
st_tre <- mean(y2hatD_tr != ytrue_tr)
cverror <- c(cverror, st_te);
cverror_train <- c(cverror_train, st_tre);
st_cm <- confusionMatrix(factor(y2hatD, levels=unique(c(y2hatD,ytrue))), factor(ytrue, levels=unique(c(y2hatD,ytrue))))
cvprecision <- c(cvprecision, st_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, st_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(st_cm$byClass["Pos Pred Value"]*st_cm$byClass["Sensitivity"])/(st_cm$byClass["Pos Pred Value"]+st_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatD), response=as.numeric(ytrue))));
#E: random forest with my chosen parameters
# best params are ntree=500, mtry=5, and nodesize=7, so use these to fit a new random forest model
set.seed(b)
rf3 <- randomForest(as.factor(Diabetes_binary) ~., data=train, ntree = 100 , mtry = 1 , nodesize = 4, importance=TRUE)
y2hatE = predict(rf3, test[,-1], type='class')
y2hatE_tr = predict(rf3, train[,-1], type='class')
rf_te <- mean(y2hatE != ytrue)
rf_tre <- mean(y2hatE_tr != ytrue_tr)
cverror <- c(cverror, rf_te);
cverror_train <- c(cverror_train, rf_tre);
rf_cm <- confusionMatrix(factor(y2hatE, levels=unique(c(y2hatE,ytrue))), factor(ytrue, levels=unique(c(y2hatE,ytrue))))
cvprecision <- c(cvprecision, rf_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, rf_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(rf_cm$byClass["Pos Pred Value"]*rf_cm$byClass["Sensitivity"])/(rf_cm$byClass["Pos Pred Value"]+rf_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatE), response=as.numeric(ytrue))));
#F: gbm with my chosen parameters
set.seed(b)
gbm.diabetes3 <- gbm(Diabetes_binary~.,data=train,
distribution = 'bernoulli',
n.trees = 500,
shrinkage = 0.15,
interaction.depth = 5,
cv.folds = 5)
## Model Inspection
set.seed(b)
perf_gbm3 = gbm.perf(gbm.diabetes3, method="cv",plot.it = FALSE)
y2hatF <- ifelse(predict(gbm.diabetes3, newdata = test[,-1], n.trees=perf_gbm3, type="response") < 0.5, 0, 1)
y2hatF_tr <- ifelse(predict(gbm.diabetes3, newdata = train[,-1], n.trees=perf_gbm3, type="response") < 0.5, 0, 1)
gbm_te <- mean(y2hatF != ytrue)
gbm_tre <- mean(y2hatF_tr != ytrue_tr)
cverror <- c(cverror, gbm_te);
cverror_train <- c(cverror_train, gbm_tre);
gbm_cm <- confusionMatrix(factor(y2hatF, levels=unique(c(y2hatF,ytrue))), factor(ytrue, levels=unique(c(y2hatF,ytrue))))
cvprecision <- c(cvprecision, gbm_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, gbm_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(gbm_cm$byClass["Pos Pred Value"]*gbm_cm$byClass["Sensitivity"])/(gbm_cm$byClass["Pos Pred Value"]+gbm_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatF), response=as.numeric(ytrue))));
#G: xbgboost with my chosen parameters
set.seed(b)
xgboost3 <- xgboost(data=as.matrix(diabetestrain[,-1]),
label = as.matrix(diabetestrain$Diabetes_binary),
nrounds = 10,
objective="binary:logistic",
eta = 0.2,
max_depth = 7,
subsample = 0.9)
y2hatG <- ifelse(predict(xgboost3, newdata = as.matrix(test[,-1]), type="response") < 0.5, 0, 1)
y2hatG_tr <- ifelse(predict(xgboost3, newdata = as.matrix(train[,-1]), type="response") < 0.5, 0, 1)
xgb_te <- mean(y2hatG != ytrue)
xgb_tre <- mean(y2hatG_tr != ytrue_tr)
cverror <- c(cverror, xgb_te);
cverror_train <- c(cverror_train, xgb_tre);
xg_cm <- confusionMatrix(factor(y2hatG, levels=unique(c(y2hatG,ytrue))), factor(ytrue, levels=unique(c(y2hatG,ytrue))))
cvprecision <- c(cvprecision, xg_cm$byClass["Pos Pred Value"]);
cvrecall <- c(cvrecall, xg_cm$byClass["Sensitivity"]);
cvF1 <- c(cvF1, 2*(xg_cm$byClass["Pos Pred Value"]*xg_cm$byClass["Sensitivity"])/(xg_cm$byClass["Pos Pred Value"]+xg_cm$byClass["Sensitivity"]));
cvAUC <- c(cvAUC, auc(roc(predictor=as.numeric(y2hatG), response=as.numeric(ytrue))));
TEALL = rbind(TEALL, cverror);
TrEALL = rbind(TrEALL, cverror_train);
PrecisionALL = rbind(PrecisionALL, cvprecision);
RecallALL = rbind(RecallALL, cvrecall);
F1ALL = rbind(F1ALL, cvF1);
AUCALL = rbind(AUCALL, cvAUC);
}
dim(TEALL); ### This should be a Bx6
colnames(TEALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(TrEALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(PrecisionALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(RecallALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(F1ALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
colnames(AUCALL) <- c("log-reg", "lda", "naive-bayes", "singletree", "randomforest", "gbm", "xgboost");
## You can report the sample mean and sample variances for the 6 models
mean_tre <- apply(TrEALL, 2, function(x) mean(x, na.rm=TRUE));
var_tre <- apply(TrEALL, 2, function(x) var(x, na.rm=TRUE));
mean_te <- apply(TEALL, 2, function(x) mean(x, na.rm=TRUE));
var_te <- apply(TEALL, 2, function(x) var(x, na.rm=TRUE));
mean_precision <- apply(PrecisionALL, 2, function(x) mean(x, na.rm=TRUE));
var_precision <- apply(PrecisionALL, 2, function(x) var(x, na.rm=TRUE));
mean_recall <- apply(RecallALL, 2, function(x) mean(x, na.rm=TRUE));
var_recall <- apply(RecallALL, 2, function(x) var(x, na.rm=TRUE));
mean_f1 <- apply(F1ALL, 2, function(x) mean(x, na.rm=TRUE));
var_f1 <- apply(F1ALL, 2, function(x) var(x, na.rm=TRUE));
mean_auc <- apply(AUCALL, 2, function(x) mean(x, na.rm=TRUE));
var_auc <- apply(AUCALL, 2, function(x) var(x, na.rm=TRUE));
best_tre <- sort((mean_tre))
best_tre
best_te <- sort((mean_te))
best_te
best_precision <- sort((mean_precision))
best_precision
best_recall <- sort((mean_recall))
best_recall
best_f1 <- sort((mean_f1))
best_f1
best_auc <- sort((mean_auc))
best_auc
best_var_te <- sort((var_te))
best_var_te
rf3 <- randomForest(as.factor(Diabetes_binary) ~., data=diabetestrain, ntree = 100 , mtry = 1 , nodesize = 4, importance=TRUE)
importance(rf3)
importance(rf3, type=2)
varImpPlot(rf3)
best_gbm_te # 0.115991
best_params2 # best params are "shrinkage = 0.05 , interaction.depth = 5" for 0.5%
perf_gbm3 # 70 at 0.5% # 42 at 20% of balanced
# make new model with best params
set.seed(123)
gbm.diabetes3 <- gbm(Diabetes_binary~.,data=diabetestrain,
distribution = 'bernoulli',
n.trees = 500,
shrinkage = 0.15,
interaction.depth = 5,
cv.folds = 5)
## Model Inspection
## Find the estimated optimal number of iterations of trees - important so we don't overfit our training data
# and we'll have poor performance on testing data
perf_gbm3 = gbm.perf(gbm.diabetes3, method="cv")
perf_gbm3 # 70 at 0.5% # 42 at 20% of balanced
## summary model
## Which variances are important
summary(gbm.diabetes3)
best_xg_te # 0.05968468
best_params3 # "eta = 0.2 , max_depth = 7 , subsample = 0.9" for 0.5%
xgboost_importance
modA
summary(modA)
######################################################################################################
# variable selection for non-ensemble methods:
set.seed(123)
full_model <- glm(as.factor(Diabetes_binary) ~., family = binomial(link="logit"), data=diabetestrain)
model_select_variables  <- stats::step(full_model, direction = "both");
## see coefficients of model_select_variables
round(coef(model_select_variables),3)
summary(model_select_variables)
# vif to check for multicollinearity
vif_results <- vif(full_model)
print(vif_results)
best_params # best params are ntree=500, mtry=5, and nodesize=7
importance(rf3)
importance(rf3, type=2)
varImpPlot(rf3)
best_gbm_te # 0.115991
best_params2 # best params are "shrinkage = 0.05 , interaction.depth = 5" for 0.5%
## Model Inspection
## Find the estimated optimal number of iterations of trees - important so we don't overfit our training data
# and we'll have poor performance on testing data
perf_gbm3 = gbm.perf(gbm.diabetes3, method="cv")
perf_gbm3 # 70 at 0.5% # 42 at 20% of balanced
## summary model
## Which variances are important
summary(gbm.diabetes3)
best_params3 # "eta = 0.2 , max_depth = 7 , subsample = 0.9" for 0.5%
xgboost_importance
best_tre <- sort((mean_tre))
best_tre
best_te <- sort((mean_te))
best_te
best_var_te
best_auc <- sort((mean_auc))
best_auc
